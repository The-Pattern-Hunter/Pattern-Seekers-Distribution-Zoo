{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 3: The Coin That Wouldn't Behave\n",
    "\n",
    "**Pages:** 41-58  \n",
    "**Word Count:** ~4,500 words  \n",
    "**Figures:** 4\n",
    "\n",
    "---\n",
    "\n",
    "## Setup: Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for all plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Story Begins\n",
    "\n",
    "One week later, Ananya stood at Professor Mishra's door with her notebook clutched against her chest like a shield. The afternoon sun hammered down on the concrete path, and she could feel sweat trickling down her back. Sambalpur in late March was unforgiving.\n",
    "\n",
    "\"Come in, come in!\" Professor's voice called before she could knock. \"The door's open, and you're letting the heat in!\"\n",
    "\n",
    "Inside, the old ceiling fan wobbled rhythmically, and Kabir was already sprawled on the floor with his own notebook, surrounded by what looked like... were those tally marks?\n",
    "\n",
    "\"You actually did it,\" Ananya said, dropping her bag and settling cross-legged beside him.\n",
    "\n",
    "\"Of course I did it. You think I'd face Professor without homework?\" Kabir gestured at his notebook. \"Fifty flips. My thumb hurts.\"\n",
    "\n",
    "Professor emerged from his small kitchen carrying three glasses of nimbu pani on a tray, ice cubes clinking. \"Homework that makes your thumb hurt is the best kind. Now, let's see what you discovered.\"\n",
    "\n",
    "### Ananya's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ananya's 50 flips (simulated based on her 24 heads result)\n",
    "ananya_flips = 50\n",
    "ananya_heads = 24\n",
    "ananya_proportion = ananya_heads / ananya_flips\n",
    "\n",
    "print(f\"Ananya's Results:\")\n",
    "print(f\"Total Flips: {ananya_flips}\")\n",
    "print(f\"Heads: {ananya_heads}\")\n",
    "print(f\"Proportion: {ananya_proportion:.2%}\")\n",
    "print(f\"\\nExpected: 50% (25 heads)\")\n",
    "print(f\"Difference: {ananya_heads - 25} heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kabir's 50 flips\n",
    "kabir_flips = 50\n",
    "kabir_heads = 27\n",
    "kabir_proportion = kabir_heads / kabir_flips\n",
    "\n",
    "print(f\"Kabir's Results:\")\n",
    "print(f\"Total Flips: {kabir_flips}\")\n",
    "print(f\"Heads: {kabir_heads}\")\n",
    "print(f\"Proportion: {kabir_proportion:.2%}\")\n",
    "print(f\"\\nExpected: 50% (25 heads)\")\n",
    "print(f\"Difference: {kabir_heads - 25} heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Professor's Question\n",
    "\n",
    "\"Twenty-four heads out of fifty flips,\" Ananya said. \"That's 48%. I thought it was supposed to be 50%?\"\n",
    "\n",
    "Kabir held up his notebook triumphantly. \"Twenty-seven heads! 54%! My coin is definitely biased toward heads.\"\n",
    "\n",
    "Professor took a long sip of his drink, eyes twinkling. \"Interesting theories. But before we conclude the coins are biased, let me ask: If I told you to meet me here at exactly 2:00 PM, and you arrived at 2:02, would you say your watch is broken?\"\n",
    "\n",
    "\"That's different,\" Kabir protested.\n",
    "\n",
    "\"Is it? You expected 25 heads. You got 24 and 27. That's pretty close.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: What Does Probability Mean?\n",
    "\n",
    "\"When we say a coin is fair‚Äîprobability 0.5 for heads‚Äîdoes that mean exactly 25 out of 50?\" Ananya asked.\n",
    "\n",
    "\"Excellent question.\" Professor set down his glass and pulled out a rupee coin from his pocket. \"Let's think about what probability actually *means*. Kabir, what does it mean to say this coin has probability 0.5 of landing heads?\"\n",
    "\n",
    "Kabir shrugged. \"Half the time it'll be heads?\"\n",
    "\n",
    "\"Half of what time? The first flip? The second? The tenth?\"\n",
    "\n",
    "\"I mean... eventually. In the long run.\"\n",
    "\n",
    "**\"Exactly right!\"** Professor slapped his knee. **\"Probability of 0.5 doesn't mean *every* flip is 50% heads‚Äîthat doesn't even make sense. One flip is either heads or tails, 100% one or the other. What it means is: *in the long run*, about half will be heads.\"**\n",
    "\n",
    "### Key Concept: Probability as Long-Run Frequency\n",
    "\n",
    "- **Individual event**: Unpredictable (could be heads OR tails)\n",
    "- **Long-run pattern**: Predictable (approaches 50% as flips increase)\n",
    "- **Probability 0.5** means: \"In the long run, approximately half will be heads\"\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: The Science Fair Idea\n",
    "\n",
    "That's when Professor told them about the school science fair.\n",
    "\n",
    "\"We should do our project on this,\" Kabir said suddenly. \"The coin flipping thing. The patterns we've been finding.\"\n",
    "\n",
    "Ananya hesitated. \"Will it count as science? It's more like... math.\"\n",
    "\n",
    "Professor nearly dropped his glass. \"Mathematics is the *language* of science! Physics, chemistry, biology‚Äîthey all depend on mathematical models. Statistics is how we make sense of messy reality.\" He leaned forward. \"Besides, you have something most science fair projects lack.\"\n",
    "\n",
    "\"What?\"\n",
    "\n",
    "\"A real question with a real answer you don't know yet.\"\n",
    "\n",
    "### The Challenge: The Great Coin-Flipping Marathon\n",
    "\n",
    "\"What happens with five hundred flips? One thousand?\"\n",
    "\n",
    "\"One thousand?\" Kabir's eyes widened. \"That's going to take forever!\"\n",
    "\n",
    "\"Science often does. But here's what I suspect you'll find: With fifty flips, randomness dominates. With a thousand flips, pattern emerges.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: The Law of Large Numbers\n",
    "\n",
    "### Concept Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Law of Large Numbers with different sample sizes\n",
    "sample_sizes = [10, 50, 100, 500, 1000]\n",
    "fig, axes = plt.subplots(1, len(sample_sizes), figsize=(20, 4))\n",
    "fig.suptitle('Law of Large Numbers: Proportion Stabilizes with More Flips', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    # Simulate coin flips\n",
    "    flips = np.random.binomial(1, 0.5, n)\n",
    "    cumulative_prop = np.cumsum(flips) / np.arange(1, n+1)\n",
    "    \n",
    "    axes[idx].plot(cumulative_prop, linewidth=2, color='steelblue')\n",
    "    axes[idx].axhline(y=0.5, color='red', linestyle='--', linewidth=2, \n",
    "                      label='True probability (0.5)', alpha=0.7)\n",
    "    axes[idx].fill_between(range(n), 0.4, 0.6, alpha=0.2, color='green')\n",
    "    axes[idx].set_title(f'n = {n} flips', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Flip Number')\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        axes[idx].set_ylabel('Proportion of Heads')\n",
    "    \n",
    "    # Add final proportion text\n",
    "    final_prop = cumulative_prop[-1]\n",
    "    axes[idx].text(0.95, 0.95, f'Final: {final_prop:.3f}', \n",
    "                   transform=axes[idx].transAxes, \n",
    "                   verticalalignment='top', horizontalalignment='right',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                   fontsize=10)\n",
    "\n",
    "axes[0].legend(loc='upper right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä OBSERVATION:\")\n",
    "print(\"Notice how the line is wild and unpredictable with few flips,\")\n",
    "print(\"but becomes smoother and closer to 0.5 as we flip more times!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professor's Explanation\n",
    "\n",
    "He drew a jagged line, starting way up at 1.0, then plunging down, then bouncing around wildly before gradually, grudgingly, settling near 0.5.\n",
    "\n",
    "\"The first few flips? Chaos. You might get three heads in a row. You might get five tails. The proportion swings wildly. But as you flip more and more times, the proportion settles down, gets closer to the true probability.\"\n",
    "\n",
    "\"It's like the coin has to catch up,\" Kabir said.\n",
    "\n",
    "**\"No! No no no.\"** Professor was suddenly animated. **\"The coin has no memory. It doesn't 'know' it's behind. Each flip is independent‚Äîpast flips don't influence future ones.\"**\n",
    "\n",
    "---\n",
    "\n",
    "## Part 5: The Marathon Begins\n",
    "\n",
    "### Simulating the 1000 Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Great Coin-Flipping Marathon: 1000 flips\n",
    "n_flips = 1000\n",
    "np.random.seed(42)  # For reproducibility\n",
    "flips = np.random.binomial(1, 0.5, n_flips)  # 1 = Heads, 0 = Tails\n",
    "\n",
    "# Calculate running statistics\n",
    "cumulative_heads = np.cumsum(flips)\n",
    "cumulative_tails = np.arange(1, n_flips+1) - cumulative_heads\n",
    "cumulative_proportion = cumulative_heads / np.arange(1, n_flips+1)\n",
    "\n",
    "# Key milestones from the story\n",
    "milestones = [50, 100, 150, 200, 300, 400, 500, 1000]\n",
    "print(\"üéØ THE GREAT COIN-FLIPPING MARATHON\\n\")\n",
    "print(\"Milestone Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for m in milestones:\n",
    "    if m <= n_flips:\n",
    "        heads = cumulative_heads[m-1]\n",
    "        prop = cumulative_proportion[m-1]\n",
    "        print(f\"After {m:4d} flips: {heads:3d} heads | Proportion: {prop:.4f} ({prop*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Story Continues...\n",
    "\n",
    "They fell into a rhythm. Kabir flipped, called out the result. Ananya recorded. Every ten flips, they paused to calculate the running proportion.\n",
    "\n",
    "**After 50 flips:** 28 heads. Proportion: 0.56 (56%)  \n",
    "**After 100 flips:** 52 heads. Proportion: 0.52 (52%)\n",
    "\n",
    "\"It's getting closer,\" Ananya said.\n",
    "\n",
    "Professor Mishra was tracking their data on a live graph on his laptop. \"Keep going. The magic happens around 500.\"\n",
    "\n",
    "**After 300 flips:** 149 heads. Proportion: 0.4967 (49.67%)  \n",
    "**After 500 flips:** 248 heads. Proportion: 0.496 (49.6%)  \n",
    "**After 1000 flips:** 497 heads, 503 tails. Proportion: 0.497 (49.7%)\n",
    "\n",
    "Kabir stared at the final number. \"We're three heads away from perfect.\"\n",
    "\n",
    "\"Three out of a thousand,\" Ananya added. \"That's 0.3% off.\"\n",
    "\n",
    "---\n",
    "\n",
    "## FIGURE 3.2: Cumulative Proportion Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dramatic visualization from the story\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Main plot: cumulative proportion\n",
    "ax.plot(range(1, n_flips+1), cumulative_proportion, \n",
    "        linewidth=2, color='steelblue', label='Running Proportion of Heads', alpha=0.8)\n",
    "\n",
    "# True probability line\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', linewidth=2.5, \n",
    "           label='True Probability (0.5)', alpha=0.9)\n",
    "\n",
    "# Confidence bands\n",
    "ax.fill_between(range(1, n_flips+1), 0.48, 0.52, alpha=0.15, color='green',\n",
    "                label='¬±2% band')\n",
    "\n",
    "# Annotate key milestones\n",
    "annotations = [\n",
    "    (10, cumulative_proportion[9], \"Wild swings\\nat start\"),\n",
    "    (200, cumulative_proportion[199], \"Starting to\\nstabilize\"),\n",
    "    (500, cumulative_proportion[499], \"Approaching\\ntrue value\"),\n",
    "    (1000, cumulative_proportion[999], f\"Final: {cumulative_proportion[999]:.4f}\")\n",
    "]\n",
    "\n",
    "for x, y, text in annotations:\n",
    "    ax.annotate(text, xy=(x, y), xytext=(x, y+0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='darkblue', lw=1.5),\n",
    "                fontsize=11, ha='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Number of Flips', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Proportion of Heads', fontsize=14, fontweight='bold')\n",
    "ax.set_title('FIGURE 3.2: The Journey from Chaos to Order\\n' +\n",
    "             'Tracking the running proportion of heads ‚Äî the line dances wildly at first\\n' +\n",
    "             'but settles near 0.5, exactly what probability predicts',\n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "ax.set_ylim([0.3, 0.8])\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='upper right', fontsize=12, framealpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà THE VISUAL IMPACT IS PROFOUND:\")\n",
    "print(\"You can SEE uncertainty transforming into confidence!\")\n",
    "print(f\"\\nFinal result: {cumulative_heads[-1]} heads out of {n_flips} flips\")\n",
    "print(f\"That's {cumulative_proportion[-1]:.4f} or {cumulative_proportion[-1]*100:.2f}%\")\n",
    "print(f\"Only {abs(cumulative_heads[-1] - 500)} flips away from perfect 50/50!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professor's Commentary\n",
    "\n",
    "\"Look at the first hundred flips,\" Professor Mishra said, pointing to the wild swings. \"Chaos. The proportion bounces between 40% and 60%. You'd never guess the true probability from that section alone.\"\n",
    "\n",
    "\"But by five hundred?\" He traced the calmer section. \"The line is hovering right around 50%, within a couple percentage points.\"\n",
    "\n",
    "\"And by a thousand?\" Ananya was mesmerized. \"It's basically there.\"\n",
    "\n",
    "**\"This is the Law of Large Numbers.\"** Professor spoke with unusual gravity. **\"It's one of the most important theorems in all of mathematics. As your sample size increases, the sample average gets closer to the expected value.\"**\n",
    "\n",
    "---\n",
    "\n",
    "## Part 6: Understanding the Math\n",
    "\n",
    "### Why Does the Proportion Settle?\n",
    "\n",
    "\"Think about it mathematically,\" Professor explained. \"After three flips, if you get two heads, that's 67%. But that's only one flip away from the expected value‚Äîyou needed 1.5 heads, got 2 heads, difference of 0.5. After a thousand flips, if you get 510 heads, that's 51%. But now you're ten flips away from expected‚Äîyou needed 500, got 510, difference of 10.\"\n",
    "\n",
    "Ananya was writing this down. \"So the law of large numbers doesn't mean the absolute difference from perfect gets smaller. It means the proportional difference gets smaller.\"\n",
    "\n",
    "\"Exactly! A ten-head surplus in a thousand flips is barely noticeable. A two-head surplus in ten flips is huge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate absolute vs proportional difference\n",
    "sample_sizes = [10, 50, 100, 500, 1000, 5000]\n",
    "results = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    flips = np.random.binomial(1, 0.5, n)\n",
    "    heads = np.sum(flips)\n",
    "    expected = n / 2\n",
    "    abs_diff = abs(heads - expected)\n",
    "    prop_diff = abs_diff / n * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Sample Size': n,\n",
    "        'Heads': heads,\n",
    "        'Expected': expected,\n",
    "        'Absolute Difference': abs_diff,\n",
    "        'Proportional Difference (%)': prop_diff\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nüìä ABSOLUTE vs PROPORTIONAL DIFFERENCE\\n\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"\\nüí° KEY INSIGHT:\")\n",
    "print(\"As sample size increases, absolute difference may grow,\")\n",
    "print(\"but proportional difference SHRINKS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize absolute vs proportional difference\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Absolute difference\n",
    "ax1.bar(range(len(df)), df['Absolute Difference'], color='coral', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xticks(range(len(df)))\n",
    "ax1.set_xticklabels(df['Sample Size'])\n",
    "ax1.set_xlabel('Sample Size', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Absolute Difference from Expected', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Absolute Difference May INCREASE', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Proportional difference\n",
    "ax2.bar(range(len(df)), df['Proportional Difference (%)'], color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(df)))\n",
    "ax2.set_xticklabels(df['Sample Size'])\n",
    "ax2.set_xlabel('Sample Size', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Proportional Difference (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('But Proportional Difference DECREASES!', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Expected Value\n",
    "\n",
    "Kabir was staring at the graph, something working in his mind. \"Professor, what if we made a game out of this? Like, heads I win ‚Çπ10, tails I lose ‚Çπ5. Would that be fair?\"\n",
    "\n",
    "Professor perked up. \"Interesting question! Let's work it out. If you play once, what could happen?\"\n",
    "\n",
    "\"I either win ten rupees or lose five.\"\n",
    "\n",
    "\"And each has probability 0.5. So on average, over many games, what would you expect to win or lose per game?\"\n",
    "\n",
    "### Calculating Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Value calculation for Kabir's game\n",
    "prob_heads = 0.5\n",
    "prob_tails = 0.5\n",
    "win_heads = 10  # rupees\n",
    "lose_tails = -5  # rupees (negative because loss)\n",
    "\n",
    "expected_value = (prob_heads * win_heads) + (prob_tails * lose_tails)\n",
    "\n",
    "print(\"\\nüé≤ KABIR'S GAME ANALYSIS\\n\")\n",
    "print(\"Game Rules:\")\n",
    "print(f\"  - Heads: WIN ‚Çπ{win_heads}\")\n",
    "print(f\"  - Tails: LOSE ‚Çπ{abs(lose_tails)}\")\n",
    "print(\"\\nExpected Value Calculation:\")\n",
    "print(f\"  E(X) = (0.5 √ó ‚Çπ{win_heads}) + (0.5 √ó ‚Çπ{lose_tails})\")\n",
    "print(f\"  E(X) = ‚Çπ{prob_heads * win_heads} + ‚Çπ{prob_tails * lose_tails}\")\n",
    "print(f\"  E(X) = ‚Çπ{expected_value}\")\n",
    "print(\"\\nüí∞ INTERPRETATION:\")\n",
    "print(f\"On average, you'd expect to win ‚Çπ{expected_value} per game.\")\n",
    "print(\"This game is FAVORABLE to the player!\")\n",
    "print(f\"\\nAfter 100 games, expected total winnings: ‚Çπ{expected_value * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate playing Kabir's game 100 times\n",
    "n_games = 100\n",
    "np.random.seed(42)\n",
    "game_results = []\n",
    "cumulative_winnings = []\n",
    "total = 0\n",
    "\n",
    "for i in range(n_games):\n",
    "    flip = np.random.binomial(1, 0.5)  # 1 = heads, 0 = tails\n",
    "    if flip == 1:  # Heads\n",
    "        result = win_heads\n",
    "    else:  # Tails\n",
    "        result = lose_tails\n",
    "    \n",
    "    game_results.append(result)\n",
    "    total += result\n",
    "    cumulative_winnings.append(total)\n",
    "\n",
    "# Plot cumulative winnings\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.plot(range(1, n_games+1), cumulative_winnings, \n",
    "        linewidth=2.5, color='darkgreen', label='Actual Cumulative Winnings')\n",
    "\n",
    "# Expected cumulative winnings line\n",
    "expected_line = [expected_value * i for i in range(1, n_games+1)]\n",
    "ax.plot(range(1, n_games+1), expected_line, \n",
    "        linewidth=2.5, color='red', linestyle='--', \n",
    "        label=f'Expected Winnings (‚Çπ{expected_value}/game)', alpha=0.8)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.3)\n",
    "ax.fill_between(range(1, n_games+1), 0, expected_line, alpha=0.1, color='green')\n",
    "\n",
    "ax.set_xlabel('Game Number', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Cumulative Winnings (‚Çπ)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Simulating 100 Games: Expected Value in Action\\n' +\n",
    "             'Notice how actual winnings track the expected value line',\n",
    "             fontsize=15, fontweight='bold', pad=15)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "\n",
    "# Add final result annotation\n",
    "ax.annotate(f'Final: ‚Çπ{total}\\n(Expected: ‚Çπ{expected_value * n_games})', \n",
    "            xy=(n_games, cumulative_winnings[-1]), \n",
    "            xytext=(n_games-20, cumulative_winnings[-1]+50),\n",
    "            arrowprops=dict(arrowstyle='->', color='darkgreen', lw=2),\n",
    "            fontsize=12, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.8', facecolor='lightyellow', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéÆ SIMULATION RESULTS:\")\n",
    "print(f\"Final winnings after {n_games} games: ‚Çπ{total}\")\n",
    "print(f\"Expected winnings: ‚Çπ{expected_value * n_games}\")\n",
    "print(f\"Average per game: ‚Çπ{total/n_games:.2f}\")\n",
    "print(f\"\\nThe actual average is close to expected value of ‚Çπ{expected_value}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to Insurance\n",
    "\n",
    "Ananya's eyes widened. \"Is this what insurance companies do? They can't predict if Uncle Bikram's crop will fail, but they predict the pattern across many farmers?\"\n",
    "\n",
    "\"Precisely! They know that maybe 5% of farmers will have crop failure in a normal year. They charge everyone a premium, knowing they'll only pay out to that 5%. The expected value calculation determines their pricing.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Part 8: The Biased Coin Experiment\n",
    "\n",
    "To test their understanding, Professor gave them a challenge: a weighted coin that lands heads 70% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate biased coin (p = 0.7 for heads)\n",
    "n_biased_flips = 200\n",
    "p_biased = 0.7\n",
    "np.random.seed(123)\n",
    "\n",
    "biased_flips = np.random.binomial(1, p_biased, n_biased_flips)\n",
    "biased_heads = np.sum(biased_flips)\n",
    "biased_proportion = biased_heads / n_biased_flips\n",
    "\n",
    "print(\"\\nü™ô THE BIASED COIN EXPERIMENT\\n\")\n",
    "print(f\"Flipped a biased coin (true probability = {p_biased}) {n_biased_flips} times\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Heads: {biased_heads}\")\n",
    "print(f\"  Tails: {n_biased_flips - biased_heads}\")\n",
    "print(f\"  Proportion: {biased_proportion:.3f} ({biased_proportion*100:.1f}%)\")\n",
    "print(f\"\\nExpected proportion: {p_biased} ({p_biased*100}%)\")\n",
    "print(f\"Difference: {abs(biased_proportion - p_biased)*100:.1f}%\")\n",
    "print(\"\\n‚úÖ The data reveals the bias!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE 3.4: Fair Coin vs. Biased Coin Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fair coin vs biased coin distributions\n",
    "# Run 20-flip experiments 1000 times for each coin\n",
    "n_experiments = 1000\n",
    "flips_per_experiment = 20\n",
    "\n",
    "np.random.seed(42)\n",
    "fair_results = [np.sum(np.random.binomial(1, 0.5, flips_per_experiment)) \n",
    "                for _ in range(n_experiments)]\n",
    "biased_results = [np.sum(np.random.binomial(1, 0.7, flips_per_experiment)) \n",
    "                  for _ in range(n_experiments)]\n",
    "\n",
    "# Create comparison plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Plot histograms\n",
    "bins = np.arange(0, 21, 1)\n",
    "ax.hist(fair_results, bins=bins, alpha=0.6, color='steelblue', \n",
    "        label='Fair Coin (p=0.5)', edgecolor='black', density=True)\n",
    "ax.hist(biased_results, bins=bins, alpha=0.6, color='coral', \n",
    "        label='Biased Coin (p=0.7)', edgecolor='black', density=True)\n",
    "\n",
    "# Add vertical lines for expected values\n",
    "ax.axvline(x=10, color='darkblue', linestyle='--', linewidth=2.5, \n",
    "           label='Fair Expected (10 heads)', alpha=0.8)\n",
    "ax.axvline(x=14, color='darkred', linestyle='--', linewidth=2.5, \n",
    "           label='Biased Expected (14 heads)', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Number of Heads (out of 20 flips)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Probability Density', fontsize=13, fontweight='bold')\n",
    "ax.set_title('FIGURE 3.4: Fair Coin vs. Biased Coin Distributions\\n' +\n",
    "             'A biased coin that lands heads 70% of the time produces a different shape ‚Äî\\n' +\n",
    "             'shifted toward more heads. The distribution reveals the coin\\'s true nature.',\n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç OBSERVATION:\")\n",
    "print(\"The SHAPE of the distribution tells you about the underlying process!\")\n",
    "print(\"Fair coin: Symmetric around 10\")\n",
    "print(\"Biased coin: Shifted toward 14\")\n",
    "print(\"\\nReal-world data is rarely perfectly symmetric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Science Fair Planning\n",
    "\n",
    "By late afternoon, they had the core of their science fair presentation:\n",
    "\n",
    "1. **Introduction**: Why patterns matter‚ÄîUncle Bikram's story\n",
    "2. **Experiment**: The thousand coin flips‚Äîdemonstrating law of large numbers\n",
    "3. **Discovery**: The bell curve emerges from our data\n",
    "4. **Explanation**: Central Limit Theorem‚Äîwhy this shape appears everywhere\n",
    "5. **Application**: Rainfall analysis‚Äîshowing the insurance company's error\n",
    "6. **Conclusion**: Mathematics as tool for justice\n",
    "\n",
    "\"It tells a complete story,\" Professor Mishra said, reviewing their outline. \"From concrete example to abstract principle to practical application. That's good science communication.\"\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ TRY THIS: Test Probability in Your Life\n",
    "\n",
    "### Activity 1: Dice Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate rolling a die 60 times\n",
    "n_rolls = 60\n",
    "np.random.seed(None)  # Use current time for randomness\n",
    "die_rolls = np.random.randint(1, 7, n_rolls)\n",
    "\n",
    "# Count each outcome\n",
    "counts = [(i, np.sum(die_rolls == i)) for i in range(1, 7)]\n",
    "expected_count = n_rolls / 6\n",
    "expected_percent = 100 / 6\n",
    "\n",
    "print(\"\\nüé≤ DICE ROLLING EXPERIMENT\\n\")\n",
    "print(f\"Rolled a die {n_rolls} times\")\n",
    "print(\"\\nResults:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Face':<10} {'Count':<10} {'Percentage':<15} {'Expected'}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for face, count in counts:\n",
    "    percent = (count / n_rolls) * 100\n",
    "    print(f\"{face:<10} {count:<10} {percent:<15.2f} {expected_percent:.2f}%\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nAre they roughly equal? Each should be near {expected_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize die roll results\n",
    "faces = [i for i, _ in counts]\n",
    "frequencies = [count for _, count in counts]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(faces, frequencies, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax.axhline(y=expected_count, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Expected ({expected_count:.1f})', alpha=0.7)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Die Face', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Dice Rolling Results: Are All Faces Equally Likely?', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(faces)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2: Expected Value Game\n",
    "\n",
    "Create a simple game and test if reality matches expected value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example game: Roll a die\n",
    "# If it's 6: Win ‚Çπ20\n",
    "# If it's 1-5: Lose ‚Çπ2\n",
    "\n",
    "prob_win = 1/6  # Rolling a 6\n",
    "prob_lose = 5/6  # Rolling 1-5\n",
    "win_amount = 20\n",
    "lose_amount = -2\n",
    "\n",
    "expected_game = (prob_win * win_amount) + (prob_lose * lose_amount)\n",
    "\n",
    "print(\"\\nüéÆ EXPECTED VALUE GAME\\n\")\n",
    "print(\"Game Rules:\")\n",
    "print(f\"  - Roll a 6: WIN ‚Çπ{win_amount}\")\n",
    "print(f\"  - Roll 1-5: LOSE ‚Çπ{abs(lose_amount)}\")\n",
    "print(\"\\nExpected Value:\")\n",
    "print(f\"  E(X) = (1/6 √ó ‚Çπ{win_amount}) + (5/6 √ó ‚Çπ{lose_amount})\")\n",
    "print(f\"  E(X) = ‚Çπ{prob_win * win_amount:.2f} + ‚Çπ{prob_lose * lose_amount:.2f}\")\n",
    "print(f\"  E(X) = ‚Çπ{expected_game:.2f} per roll\")\n",
    "print(f\"\\n{'Is this a good game to play?' if expected_game > 0 else 'This game favors the house!'}\")\n",
    "\n",
    "# Simulate playing 20 times\n",
    "n_games = 20\n",
    "np.random.seed(None)\n",
    "total_winnings = 0\n",
    "results = []\n",
    "\n",
    "print(f\"\\nüé≤ Playing {n_games} times...\\n\")\n",
    "for i in range(1, n_games+1):\n",
    "    roll = np.random.randint(1, 7)\n",
    "    if roll == 6:\n",
    "        winnings = win_amount\n",
    "        outcome = \"WIN\"\n",
    "    else:\n",
    "        winnings = lose_amount\n",
    "        outcome = \"LOSE\"\n",
    "    total_winnings += winnings\n",
    "    results.append(total_winnings)\n",
    "    if i <= 5 or i > n_games-3:  # Show first 5 and last 2\n",
    "        print(f\"Game {i}: Rolled {roll} ‚Üí {outcome} ‚Çπ{abs(winnings)} | Total: ‚Çπ{total_winnings}\")\n",
    "    elif i == 6:\n",
    "        print(\"...\")\n",
    "\n",
    "average_per_game = total_winnings / n_games\n",
    "print(f\"\\nüìä RESULTS:\")\n",
    "print(f\"Total winnings: ‚Çπ{total_winnings}\")\n",
    "print(f\"Average per game: ‚Çπ{average_per_game:.2f}\")\n",
    "print(f\"Expected per game: ‚Çπ{expected_game:.2f}\")\n",
    "print(f\"\\nDifference: ‚Çπ{abs(average_per_game - expected_game):.2f}\")\n",
    "print(\"\\nüí° With more games, the average gets closer to expected value!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Key Concepts from Chapter 3\n",
    "\n",
    "### 1. Probability as Long-Run Frequency\n",
    "- Probability 0.5 doesn't mean every flip is 50% heads\n",
    "- It means: in the long run, about half will be heads\n",
    "- Individual events are unpredictable, but patterns emerge\n",
    "\n",
    "### 2. Law of Large Numbers\n",
    "- As sample size increases, sample average approaches expected value\n",
    "- Absolute difference may grow, but proportional difference shrinks\n",
    "- Small samples: Randomness dominates\n",
    "- Large samples: Pattern emerges\n",
    "\n",
    "### 3. Expected Value\n",
    "- Weighted average of all possible outcomes\n",
    "- Formula: E(X) = Œ£ [P(outcome) √ó value of outcome]\n",
    "- Doesn't predict individual result\n",
    "- Predicts long-run average\n",
    "- Used in insurance, gambling, decision-making\n",
    "\n",
    "### 4. Distribution Reveals True Nature\n",
    "- Fair coin: Symmetric distribution centered at p=0.5\n",
    "- Biased coin: Shifted distribution\n",
    "- Shape of distribution tells you about underlying process\n",
    "- Real-world data is rarely perfectly symmetric\n",
    "\n",
    "---\n",
    "\n",
    "## üîó References\n",
    "\n",
    "1. Mlodinow, L. (2008). *The Drunkard's Walk: How Randomness Rules Our Lives*. Pantheon Books.\n",
    "\n",
    "2. Bernoulli, J. (1713). *Ars Conjectandi*. [Historical reference - Law of Large Numbers]\n",
    "\n",
    "3. Gigerenzer, G. (2002). *Calculated Risks: How to Know When Numbers Deceive You*. Simon & Schuster.\n",
    "\n",
    "---\n",
    "\n",
    "## üí≠ Reflection Questions\n",
    "\n",
    "1. Why can't we predict individual coin flips, but we can predict patterns?\n",
    "\n",
    "2. If you flip a coin 10 times and get 7 heads, does the coin \"owe\" you tails? Why or why not?\n",
    "\n",
    "3. How does insurance pricing relate to expected value?\n",
    "\n",
    "4. Why is a large sample size important for detecting if a coin is biased?\n",
    "\n",
    "5. Can you think of a situation in your life where you've observed the Law of Large Numbers in action?\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Next Chapter Preview\n",
    "\n",
    "**Chapter 4: The Shape of Uncertainty**\n",
    "\n",
    "Two weeks after the Great Coin-Flipping Marathon, Ananya and Kabir present their science fair project. They discover that coin flips and monsoon rainfall follow the same mysterious pattern: the bell curve, or normal distribution. But why? What's so special about this shape? And how can it help them understand Uncle Bikram's insurance claim?\n",
    "\n",
    "The adventure continues as they explore the Central Limit Theorem‚Äîone of the most powerful ideas in all of statistics...\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 3**\n",
    "\n",
    "*\"Pattern emerging from chaos‚Äîthat's the law of large numbers.\"* ‚Äî Professor Mishra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
